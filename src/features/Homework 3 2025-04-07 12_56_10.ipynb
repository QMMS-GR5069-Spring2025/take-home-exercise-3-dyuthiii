{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e0ddd60-ca01-4e0d-b1ab-dea79a1c5ed3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#%python\n",
    "#%pip install mlflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65af570b-71ca-45ff-bfcf-45558eba8caa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "from pyspark.sql.functions import avg, current_date, col, year, date_diff,floor, count\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "import boto3\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "190f9b12-075e-4f08-83d3-fb5026326768",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#reading in data from AWs\n",
    "drivers_df = spark.read.csv('s3://columbia-gr5069-main/raw/drivers.csv', \n",
    "                            header=True)\n",
    "display(drivers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75670238-f169-42b9-8dc8-4dcf0bd039eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "driver_standings_df = spark.read.csv('s3://columbia-gr5069-main/raw/driver_standings.csv', \n",
    "                            header=True)\n",
    "display(driver_standings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "694e8a41-e87c-4704-9e69-01b9d6da043f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pitstops_df = spark.read.csv('s3://columbia-gr5069-main/raw/pit_stops.csv', \n",
    "                            header=True)\n",
    "display(pitstops_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05ae6214-d9c5-47a2-b26a-881600658d22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merged_df = driver_standings_df.join(drivers_df, on='driverId')\n",
    "merged_df = merged_df.join(pitstops_df, on=['raceId','driverId'])\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aa32e13-36fe-4a15-a4c5-b760234699e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating an age column\n",
    "#calclating AGE for each driver and adding it to the merged df\n",
    "merged_df = merged_df.withColumn('age', floor(date_diff(current_date(), 'dob') / 365))\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d721eec-8b64-4bdb-896a-7533e8792ecb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Running a regression model using random forest to predict position based on driverId, age, wins. number of pitstop stops, and pitstop duration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00c9d43b-fc31-4884-9a52-b56848961548",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#converting to float and then merging\n",
    "merged_rfVars_df = merged_df.select('raceId','driverId','age','wins', 'position', 'stop', 'duration').selectExpr('cast(age as int) as age', 'cast(wins as int) as wins', 'cast(position as int) as position', 'cast(stop as int) as stop', 'cast(duration as float) as duration', 'cast(raceId as int) as raceId', 'cast(driverId as int) as driverId').dropna(how=\"any\")\n",
    "display(merged_rfVars_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5fffe69-5988-499c-ae9c-7c64951928bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "grouping by raceID before train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "874c60f6-ea5e-4aac-8f3d-3b5e31cc50da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(merged_rfVars_df.select('driverId','age', 'wins', 'raceId', 'duration','stop').toPandas(), merged_rfVars_df[['position']].toPandas().values.ravel(), random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e30bf10-692a-43bf-bc39-b0b51f9abd18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "sklearn.ensemble.HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5595572b-ce6b-49d5-ad5a-0c1c2c11abf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Basic RF Experiment\") as run:\n",
    "  # Create model, train it, and create predictions\n",
    "  rf = RandomForestRegressor()\n",
    "  rf.fit(X_train, y_train)\n",
    "  predictions = rf.predict(X_test)\n",
    "  \n",
    "  # Log model\n",
    "  mlflow.sklearn.log_model(rf, \"RandomForestRegressor-model\")\n",
    "  \n",
    "  # Create metrics\n",
    "  mse = mean_squared_error(y_test, predictions)\n",
    "  print(\"  mse: {}\".format(mse))\n",
    "  \n",
    "  # Log metrics\n",
    "  mlflow.log_metric(\"mse\", mse)\n",
    "  \n",
    "  runID = run.info.run_uuid\n",
    "  experimentID = run.info.experiment_id\n",
    "  \n",
    "  print(\"Inside MLflow Run with run_id {} and experiment_id {}\".format(runID, experimentID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26286c48-ddd3-4fca-b786-da81c0180f47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def log_rf(experimentID, run_name, params, X_train, X_test, y_train, y_test):\n",
    "  import os\n",
    "  import matplotlib.pyplot as plt\n",
    "  import mlflow.sklearn\n",
    "  import seaborn as sns\n",
    "  from sklearn.ensemble import RandomForestRegressor\n",
    "  from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "  import tempfile\n",
    "\n",
    "  with mlflow.start_run(experiment_id=experimentID, run_name=run_name) as run:\n",
    "    # Create model, train it, and create predictions\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(rf, \"RandomForestRegressor-model\")\n",
    "\n",
    "    # Log params\n",
    "    [mlflow.log_param(param, value) for param, value in params.items()]\n",
    "\n",
    "    # Create metrics\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    print(\"  mse: {}\".format(mse))\n",
    "    print(\"  mae: {}\".format(mae))\n",
    "    print(\"  R2: {}\".format(r2))\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"mae\", mae)  \n",
    "    mlflow.log_metric(\"r2\", r2)  \n",
    "    \n",
    "    # Create feature importance\n",
    "    importance = pd.DataFrame(list(zip(merged_rfVars_df.columns, rf.feature_importances_)), \n",
    "                                columns=[\"Feature\", \"Importance\"]\n",
    "                              ).sort_values(\"Importance\", ascending=False)\n",
    "    \n",
    "    # Log importances using a temporary file\n",
    "    temp = tempfile.NamedTemporaryFile(prefix=\"feature-importance-\", suffix=\".csv\")\n",
    "    temp_name = temp.name\n",
    "    try:\n",
    "      importance.to_csv(temp_name, index=False)\n",
    "      mlflow.log_artifact(temp_name, \"feature-importance.csv\")\n",
    "    finally:\n",
    "      temp.close() # Delete the temp file\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    sns.residplot(x=predictions, y=y_test, lowess=True)\n",
    "    plt.xlabel(\"Predicted values for Postition\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.title(\"Residual Plot\")\n",
    "\n",
    "    # Log residuals using a temporary file\n",
    "    temp = tempfile.NamedTemporaryFile(prefix=\"residuals-\", suffix=\".png\")\n",
    "    temp_name = temp.name\n",
    "    try:\n",
    "      fig.savefig(temp_name)\n",
    "      mlflow.log_artifact(temp_name, \"residuals.png\")\n",
    "    finally:\n",
    "      temp.close() # Delete the temp file\n",
    "      \n",
    "    display(fig)\n",
    "    return run.info.run_uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85f8b959-7f82-4e22-9bd7-3cd847a3cd8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "  \"n_estimators\": 100,\n",
    "  \"max_depth\": 5,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Second Run\", params, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "405f3d8c-a8a5-4295-9462-7bb2326f8ff3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params_1000_trees = {\n",
    "  \"n_estimators\": 1000,\n",
    "  \"max_depth\": 10,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Third Run\", params_1000_trees, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06d2e9c9-7171-46dd-9ba3-500b7b609df2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params_500_trees = {\n",
    "  \"n_estimators\": 500,\n",
    "  \"max_depth\": 10,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Fourth Run\", params_500_trees, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1707500c-7b80-4ca8-9602-2e6ebbfe0c43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params_1000_5trees = {\n",
    "  \"n_estimators\": 1000,\n",
    "  \"max_depth\": 5,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"fifth Run\", params_1000_5trees, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a95db665-3d3d-4c66-b9e1-8b49662a76a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params_1000_15trees = {\n",
    "  \"n_estimators\": 1000,\n",
    "  \"max_depth\": 15,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Sixth Run\", params_1000_15trees, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bc9665d-c5f0-4b14-b963-285a1b534dfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params_10000_trees = {\n",
    "  \"n_estimators\": 10000,\n",
    "  \"max_depth\": 10,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Seventh Run\", params_10000_trees, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "216e4df7-338f-4844-b56b-ca212e7b56dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params_1000_20trees = {\n",
    "  \"n_estimators\": 1000,\n",
    "  \"max_depth\": 20,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Eighth Run\", params_1000_20trees, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9a1fe40-d668-4664-989b-dd2096d3bb4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params_1000_25trees = {\n",
    "  \"n_estimators\": 1000,\n",
    "  \"max_depth\": 25,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Ninth Run\", params_1000_25trees, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "922c591e-0aaf-40ef-87b5-07f0cf4416a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params_2000_20trees = {\n",
    "  \"n_estimators\": 2000,\n",
    "  \"max_depth\": 20,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Tenth Run\", params_2000_20trees, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7ce5654-c669-4a8e-a727-6499e85c0d80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The best model seems to be the one with 1000 estimators, with max_depth = 25. This is the \"Ninth Run\", and it also has the least mean square error (mse) and mean absolute error (mae).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2df26247-4df0-455c-af2b-767f095a23ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Homework 3 2025-04-07 12_56_10",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
